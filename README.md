#Simple linear regression with gradient descent

##Overview
Implementation of gradient descent algorithm on a simple linear regression problem.

First a noisy dataset (*y = 9x + 20*) is created; then, each step of the gradient descent algorithm is implemented and used to "learn" the *w* and *b* weights of the linear model. After training, plots of both mean square error (cost function) and linear regression are shown. Finally, the model is used to perform a predictition on new data.

##Dependencies
matplotlib==2.0.0
numpy==1.14.0


